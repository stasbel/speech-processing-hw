{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets.lfw import Bunch\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Bunch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.data_path = '/app/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COPYING  README  speaker-info.txt  txt\twav48\r\n"
     ]
    }
   ],
   "source": [
    "!ls $args.data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/app/data/wav48/p225/p225_067.wav',\n",
       " '/app/data/wav48/p225/p225_224.wav',\n",
       " '/app/data/wav48/p225/p225_173.wav']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav48path = os.path.join(args.data_path, 'wav48/p225')\n",
    "txtpath = os.path.join(args.data_path, 'txt')\n",
    "wav48 = [wav48path + '/' + f for f in os.listdir(wav48path)]\n",
    "random.sample(wav48, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/app/data/txt/p225/p225_122.txt',\n",
       " '/app/data/txt/p225/p225_115.txt',\n",
       " '/app/data/txt/p225/p225_174.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = [file.replace('wav48', 'txt').replace('.wav', '.txt') for file in wav48]\n",
    "random.sample(txt, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in txt:\n",
    "    if not os.path.exists(t):\n",
    "        print(t)\n",
    "        txt.remove(t)\n",
    "        wav48.remove(t.replace('txt', 'wav48').replace('.txt', '.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/app/data/wav48/p225/p225_072.wav</td>\n",
       "      <td>/app/data/txt/p225/p225_072.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/app/data/wav48/p225/p225_274.wav</td>\n",
       "      <td>/app/data/txt/p225/p225_274.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/app/data/wav48/p225/p225_254.wav</td>\n",
       "      <td>/app/data/txt/p225/p225_254.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/app/data/wav48/p225/p225_358.wav</td>\n",
       "      <td>/app/data/txt/p225/p225_358.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/app/data/wav48/p225/p225_359.wav</td>\n",
       "      <td>/app/data/txt/p225/p225_359.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   0                                1\n",
       "0  /app/data/wav48/p225/p225_072.wav  /app/data/txt/p225/p225_072.txt\n",
       "1  /app/data/wav48/p225/p225_274.wav  /app/data/txt/p225/p225_274.txt\n",
       "2  /app/data/wav48/p225/p225_254.wav  /app/data/txt/p225/p225_254.txt\n",
       "3  /app/data/wav48/p225/p225_358.wav  /app/data/txt/p225/p225_358.txt\n",
       "4  /app/data/wav48/p225/p225_359.wav  /app/data/txt/p225/p225_359.txt"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(list(zip(wav48, txt)))\n",
    "train, test = pd.DataFrame(train), pd.DataFrame(test)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"train.csv\", index=False, header=False)\n",
    "test.to_csv(\"test.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr 13 17:09:06 2018       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 384.111                Driver Version: 384.111                   |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 50%   72C    P2    88W / 250W |   1150MiB / 11171MiB |    100%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "| 69%   83C    P2   115W / 250W |   9689MiB / 11172MiB |     99%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 48%   69C    P2    85W / 250W |   3007MiB / 11172MiB |    100%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 108...  Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 52%   76C    P2    82W / 250W |  10816MiB / 11172MiB |    100%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: train.py [-h] [--train-manifest DIR] [--val-manifest DIR]\n",
      "                [--sample-rate SAMPLE_RATE] [--batch-size BATCH_SIZE]\n",
      "                [--num-workers NUM_WORKERS] [--labels-path LABELS_PATH]\n",
      "                [--window-size WINDOW_SIZE] [--window-stride WINDOW_STRIDE]\n",
      "                [--window WINDOW] [--hidden-size HIDDEN_SIZE]\n",
      "                [--hidden-layers HIDDEN_LAYERS] [--rnn-type RNN_TYPE]\n",
      "                [--epochs EPOCHS] [--cuda] [--lr LR] [--momentum MOMENTUM]\n",
      "                [--max-norm MAX_NORM] [--learning-anneal LEARNING_ANNEAL]\n",
      "                [--silent] [--checkpoint]\n",
      "                [--checkpoint-per-batch CHECKPOINT_PER_BATCH] [--visdom]\n",
      "                [--tensorboard] [--log-dir LOG_DIR] [--log-params] [--id ID]\n",
      "                [--save-folder SAVE_FOLDER] [--model-path MODEL_PATH]\n",
      "                [--continue-from CONTINUE_FROM] [--finetune] [--augment]\n",
      "                [--noise-dir NOISE_DIR] [--noise-prob NOISE_PROB]\n",
      "                [--noise-min NOISE_MIN] [--noise-max NOISE_MAX] [--no-shuffle]\n",
      "                [--no-sortaGrad] [--no-bidirectional] [--dist-url DIST_URL]\n",
      "                [--dist-backend DIST_BACKEND] [--world-size WORLD_SIZE]\n",
      "                [--rank RANK] [--gpu-rank GPU_RANK]\n",
      "\n",
      "DeepSpeech training\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --train-manifest DIR  path to train manifest csv\n",
      "  --val-manifest DIR    path to validation manifest csv\n",
      "  --sample-rate SAMPLE_RATE\n",
      "                        Sample rate\n",
      "  --batch-size BATCH_SIZE\n",
      "                        Batch size for training\n",
      "  --num-workers NUM_WORKERS\n",
      "                        Number of workers used in data-loading\n",
      "  --labels-path LABELS_PATH\n",
      "                        Contains all characters for transcription\n",
      "  --window-size WINDOW_SIZE\n",
      "                        Window size for spectrogram in seconds\n",
      "  --window-stride WINDOW_STRIDE\n",
      "                        Window stride for spectrogram in seconds\n",
      "  --window WINDOW       Window type for spectrogram generation\n",
      "  --hidden-size HIDDEN_SIZE\n",
      "                        Hidden size of RNNs\n",
      "  --hidden-layers HIDDEN_LAYERS\n",
      "                        Number of RNN layers\n",
      "  --rnn-type RNN_TYPE   Type of the RNN. rnn|gru|lstm are supported\n",
      "  --epochs EPOCHS       Number of training epochs\n",
      "  --cuda                Use cuda to train model\n",
      "  --lr LR, --learning-rate LR\n",
      "                        initial learning rate\n",
      "  --momentum MOMENTUM   momentum\n",
      "  --max-norm MAX_NORM   Norm cutoff to prevent explosion of gradients\n",
      "  --learning-anneal LEARNING_ANNEAL\n",
      "                        Annealing applied to learning rate every epoch\n",
      "  --silent              Turn off progress tracking per iteration\n",
      "  --checkpoint          Enables checkpoint saving of model\n",
      "  --checkpoint-per-batch CHECKPOINT_PER_BATCH\n",
      "                        Save checkpoint per batch. 0 means never save\n",
      "  --visdom              Turn on visdom graphing\n",
      "  --tensorboard         Turn on tensorboard graphing\n",
      "  --log-dir LOG_DIR     Location of tensorboard log\n",
      "  --log-params          Log parameter values and gradients\n",
      "  --id ID               Identifier for visdom/tensorboard run\n",
      "  --save-folder SAVE_FOLDER\n",
      "                        Location to save epoch models\n",
      "  --model-path MODEL_PATH\n",
      "                        Location to save best validation model\n",
      "  --continue-from CONTINUE_FROM\n",
      "                        Continue from checkpoint model\n",
      "  --finetune            Finetune the model from checkpoint \"continue_from\"\n",
      "  --augment             Use random tempo and gain perturbations.\n",
      "  --noise-dir NOISE_DIR\n",
      "                        Directory to inject noise into audio. If default,\n",
      "                        noise Inject not added\n",
      "  --noise-prob NOISE_PROB\n",
      "                        Probability of noise being added per sample\n",
      "  --noise-min NOISE_MIN\n",
      "                        Minimum noise level to sample from. (1.0 means all\n",
      "                        noise, not original signal)\n",
      "  --noise-max NOISE_MAX\n",
      "                        Maximum noise levels to sample from. Maximum 1.0\n",
      "  --no-shuffle          Turn off shuffling and sample from dataset based on\n",
      "                        sequence length (smallest to largest)\n",
      "  --no-sortaGrad        Turn off ordering of dataset on sequence length for\n",
      "                        the first epoch.\n",
      "  --no-bidirectional    Turn off bi-directional RNNs, introduces lookahead\n",
      "                        convolution\n",
      "  --dist-url DIST_URL   url used to set up distributed training\n",
      "  --dist-backend DIST_BACKEND\n",
      "                        distributed backend\n",
      "  --world-size WORLD_SIZE\n",
      "                        number of distributed processes\n",
      "  --rank RANK           The rank of this process\n",
      "  --gpu-rank GPU_RANK   If using distributed parallel for multi-gpu, sets the\n",
      "                        GPU for the process\n"
     ]
    }
   ],
   "source": [
    "%run train.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Save directory already exists.\n",
      "DataParallel(\n",
      "  (module): DeepSpeech(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d (1, 32, kernel_size=(41, 11), stride=(2, 2), padding=(0, 10))\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (2): Hardtanh(min_val=0, max_val=20, inplace)\n",
      "      (3): Conv2d (32, 32, kernel_size=(21, 11), stride=(2, 1))\n",
      "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (5): Hardtanh(min_val=0, max_val=20, inplace)\n",
      "    )\n",
      "    (rnns): Sequential(\n",
      "      (0): BatchRNN(\n",
      "        (rnn): GRU(672, 800, bias=False, bidirectional=True)\n",
      "      )\n",
      "      (1): BatchRNN(\n",
      "        (batch_norm): SequenceWise (\n",
      "        BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True))\n",
      "        (rnn): GRU(800, 800, bias=False, bidirectional=True)\n",
      "      )\n",
      "      (2): BatchRNN(\n",
      "        (batch_norm): SequenceWise (\n",
      "        BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True))\n",
      "        (rnn): GRU(800, 800, bias=False, bidirectional=True)\n",
      "      )\n",
      "      (3): BatchRNN(\n",
      "        (batch_norm): SequenceWise (\n",
      "        BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True))\n",
      "        (rnn): GRU(800, 800, bias=False, bidirectional=True)\n",
      "      )\n",
      "      (4): BatchRNN(\n",
      "        (batch_norm): SequenceWise (\n",
      "        BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True))\n",
      "        (rnn): GRU(800, 800, bias=False, bidirectional=True)\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): SequenceWise (\n",
      "      Sequential(\n",
      "        (0): BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (1): Linear(in_features=800, out_features=29)\n",
      "      ))\n",
      "    )\n",
      "    (inference_softmax): InferenceBatchSoftmax(\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Number of parameters: 38067968\n",
      "Epoch: [1][1/44]\tTime 2.970 (2.970)\tData 0.727 (0.727)\tLoss 1881.0813 (1881.0813)\t\n",
      "Epoch: [1][2/44]\tTime 2.204 (2.587)\tData 0.004 (0.365)\tLoss 1534.7666 (1707.9240)\t\n",
      "Epoch: [1][3/44]\tTime 2.223 (2.465)\tData 0.001 (0.244)\tLoss 730.5546 (1382.1342)\t\n",
      "Epoch: [1][4/44]\tTime 1.902 (2.325)\tData 0.003 (0.184)\tLoss 137.5154 (1070.9795)\t\n",
      "Epoch: [1][5/44]\tTime 1.903 (2.240)\tData 0.012 (0.149)\tLoss 30.5511 (862.8938)\t\n",
      "Epoch: [1][6/44]\tTime 2.645 (2.308)\tData 0.005 (0.125)\tLoss 129.1165 (740.5976)\t\n",
      "Epoch: [1][7/44]\tTime 1.717 (2.223)\tData 0.013 (0.109)\tLoss 40.4837 (640.5813)\t\n",
      "Epoch: [1][8/44]\tTime 1.479 (2.130)\tData 0.001 (0.096)\tLoss 16.0331 (562.5128)\t\n",
      "Epoch: [1][9/44]\tTime 2.904 (2.216)\tData 0.002 (0.085)\tLoss 117.9372 (513.1155)\t\n",
      "Epoch: [1][10/44]\tTime 2.286 (2.223)\tData 0.002 (0.077)\tLoss 21.4977 (463.9537)\t\n",
      "Epoch: [1][11/44]\tTime 1.577 (2.164)\tData 0.002 (0.070)\tLoss 11.2267 (422.7967)\t\n",
      "Epoch: [1][12/44]\tTime 4.224 (2.336)\tData 0.002 (0.064)\tLoss 20.9692 (389.3111)\t\n",
      "Epoch: [1][13/44]\tTime 1.924 (2.304)\tData 0.003 (0.060)\tLoss 12.5118 (360.3265)\t\n",
      "Epoch: [1][14/44]\tTime 1.446 (2.243)\tData 0.002 (0.056)\tLoss 31.4497 (336.8353)\t\n",
      "Epoch: [1][15/44]\tTime 1.624 (2.202)\tData 0.012 (0.053)\tLoss 16.3808 (315.4717)\t\n",
      "Epoch: [1][16/44]\tTime 1.737 (2.173)\tData 0.002 (0.050)\tLoss 12.3652 (296.5275)\t\n",
      "Epoch: [1][17/44]\tTime 2.028 (2.164)\tData 0.002 (0.047)\tLoss 12.4896 (279.8194)\t\n",
      "Epoch: [1][18/44]\tTime 3.131 (2.218)\tData 0.002 (0.044)\tLoss 19.2696 (265.3444)\t\n",
      "Epoch: [1][19/44]\tTime 1.898 (2.201)\tData 0.019 (0.043)\tLoss 70.7408 (255.1021)\t\n",
      "Epoch: [1][20/44]\tTime 2.234 (2.203)\tData 0.017 (0.042)\tLoss 19.4663 (243.3203)\t\n",
      "Epoch: [1][21/44]\tTime 1.907 (2.189)\tData 0.003 (0.040)\tLoss 18.6517 (232.6218)\t\n",
      "Epoch: [1][22/44]\tTime 2.859 (2.219)\tData 0.002 (0.038)\tLoss 9.9002 (222.4981)\t\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=2 python train.py --train-manifest train.csv --val-manifest test.csv --epochs 3 --batch-size 4 --labels-path=labels.json --cuda"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
